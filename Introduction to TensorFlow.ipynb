{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to TensorFlow\n",
    "\n",
    "Welcome to TensorFlow! In this introduction we will go through the basics of TensorFlow so that we can understand how the package works. We won't being going over neural networks in this tutorial, but throughout the tutorial, you can see how we are heading towards the direction of building neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Installation\n",
    "\n",
    "Follow https://www.tensorflow.org/install/ for installing tensorflow, and make sure you have Python installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Tensor\n",
    "\n",
    "A \"tensor\" is a representation of data in tensorflow as an n-dimensional matrix. \n",
    "\n",
    "- a tensor of rank 0 is: 5\n",
    "- a tensor of rank 1 is: [5,6,7] (shape [3])\n",
    "- a tensor of rank 2 is: [[1,2,3], [2,3,4]] (shape [2,3])\n",
    "- and so on so forth...\n",
    "\n",
    "Once we import tensorflow we can define constants. tensorflow also supports type inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "num1 = tf.constant(5.0, tf.float32)\n",
    "num2 = tf.constant(7.0)\n",
    "print(num1, num2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Sessions\n",
    "\n",
    "The nodes we created can't actually be used until we start a session (their values aren't evaluated until we are in a session). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run([num1, num2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create nodes which perform operations like addition, and apply them to other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n"
     ]
    }
   ],
   "source": [
    "op1 = tf.add(num1, num2)\n",
    "print(sess.run(op1)) \n",
    "# alternatively we could also do sess.run(num1 + num2), but this\n",
    "# shows the overall structure of how Tensorflow works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders\n",
    "Placeholders in tensorflow can be thought of nodes which are waiting to receive a value.\n",
    "\n",
    "Notice up until now that our nodes represent a structure of computation. It is not until we run a session that we feed data into our nodes and we retrieve an output - you can think of this as lazy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "sum_x_y = x + y # tf.add is overloaded with the + operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With sum_x_y, we can pass it any kind of data for x and y, and it will be able to add our values up (as long as the shapes are the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(sum_x_y, {x: 5, y: 7}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.  11.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(sum_x_y, {x: [5, 7], y: [2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we can also create operations upon other operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14.  22.]\n"
     ]
    }
   ],
   "source": [
    "sum_times_2 = sum_x_y * 2\n",
    "\n",
    "print(sess.run(sum_times_2, {x: [5, 7], y: [2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputting Graph to TensorBoard\n",
    "We can write our session graph to a file using FileWriter. Then we can view the graph via tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one = tf.constant(5, name='node_1')\n",
    "two = tf.constant(2, name='node_2')\n",
    "three = tf.multiply(one, two, name='node_3')\n",
    "sess1 = tf.Session()\n",
    "output = sess1.run(three)\n",
    "writer = tf.summary.FileWriter('./my_graph', sess1.graph)\n",
    "writer.close()\n",
    "sess1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Linear Model\n",
    "Variables in tensorflow have a value, and this value is mutable. Variables are especially useful while training our models so that they can be adjusted for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = tf.Variable([.5])\n",
    "bias = tf.Variable([-.5])\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "linear_model = weights * x + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables have to be initialized. To do so we use tf.global_variables_initializer, and pass that to our session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5  0.   0.5  1. ]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print(sess.run(linear_model, {x: [0,1,2,3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we can see, when we run our session each input is ran through the linear model we build. If we want to see the squared error of our model, we can build more tensors as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.0\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_errors = tf.square(linear_model - y)\n",
    "total_error = tf.reduce_sum(squared_errors)\n",
    "print(sess.run(total_error, {x: [0, 1, 2, 3], y: [2.5, 3, 3.5, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Linear Model\n",
    "Recall that in order for our model to learn, we must define a loss function. This way, we can perform gradient descent and adjust the properties of our model so that it can minimize loss. Below, we have constructed a new Tensor which performs gradient descent, and we provide it with the learning rate and which tensor to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradient_descent = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_model = gradient_descent.minimize(total_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've constructed our gradient descent tensor, we will do sess.run(init), to reinitialize our weight and bias to .5 and -.5 respectively. Then we will run gradient descent 800 times and then view the new error, weight, and bias. Ideally, this would produce a model with the slope = 0.5, intercept = 2.5, and error = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0 Error:  20.3616\n",
      "iteration:  100 Error:  0.0677404\n",
      "iteration:  200 Error:  0.000548328\n",
      "iteration:  300 Error:  4.43594e-06\n",
      "iteration:  400 Error:  3.59472e-08\n",
      "iteration:  500 Error:  2.96495e-10\n",
      "iteration:  600 Error:  2.63753e-11\n",
      "iteration:  700 Error:  2.63753e-11\n",
      "Error:  2.63753e-11\n",
      "Weight:  [ 0.50000191] Bias:  [ 2.49999571]\n"
     ]
    }
   ],
   "source": [
    "sess.run(init)\n",
    "\n",
    "for i in range(800):\n",
    "    sess.run(train_model, {x: [0, 1, 2, 3],\n",
    "                     y: [2.5, 3, 3.5, 4]})\n",
    "    if i % 100 == 0:\n",
    "        print('iteration: ', i, 'Error: ', sess.run(total_error, {x: [0, 1, 2, 3], y: [2.5, 3, 3.5, 4]}))\n",
    "print('Error: ', sess.run(total_error, {x: [0, 1, 2, 3], y: [2.5, 3, 3.5, 4]}))\n",
    "print('Weight: ', sess.run(weights), 'Bias: ', sess.run(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Recap of Tensors:\n",
    "\n",
    "- You can think of a tensor as a representation of a multidimensional array or vector\n",
    "  - tf.constant: A tensor which has a constant value. That value is whatever you define it to be\n",
    "  - tf.placeholder: A tensor which dosen't have a value until you run a session and provide that tensor with data.\n",
    "  - tf.Variable: A tensor which has an initial value, but that value can change as we optimize different functions (think of it as a constant which can change)\n",
    "  - Tensors can also be operations or optimizers like matrix multiplication or gradient descent.\n",
    "- Remember that tensors are different from vectors or arrays in python. You will always \"load\" your python vector or array into tensorflow by using a placeholder tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 1:\n",
    "\n",
    "Try outputting the graph for training a linear model and see how it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 2:\n",
    "\n",
    "Using the code below, build a linear regression model using tensorflow. The dataset we will be using is the boston housing dataset. This dataset has features for a home, and the label is a home's median value in $1000s. To read more about this dataset, visit https://www.kaggle.com/c/boston-housing. The code block below loads the dataset and performs all the preprocessing required. From here, use the training sets to train a linear model, then print the MSE of your model using the testing set. Keep in mind that the shape of this dataset is multidimensional, so you will need to account for that while building your tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib import learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "boston = learn.datasets.load_dataset('boston')\n",
    "x, y = boston.data, boston.target\n",
    "y.resize( y.size, 1 ) #make y = [[x], [x], [x], ... ]\n",
    "\n",
    "rnd_indices = np.random.rand(len(x)) < 0.80\n",
    "\n",
    "train_x = x[rnd_indices]\n",
    "train_y = y[rnd_indices]\n",
    "test_x = x[~rnd_indices]\n",
    "test_y = y[~rnd_indices]\n",
    "\n",
    "scaler = preprocessing.StandardScaler( )\n",
    "train_x = scaler.fit_transform( train_x )\n",
    "test_x = scaler.fit_transform( test_x )\n",
    "\n",
    "n_dim = train_x.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Solution:\n",
    "Here we are predefining our learning rate and # of training iterations. We will also keep an array to hold our model's cost while training so that we can visualize it later. Now since we are dealing with multidimensional data, we need to define our X placeholder and weights in terms of the number of features we have. From here, our linear model will perform a matrix multiplication of teh weights and inputs, and then add the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "cost_history = []\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,n_dim])\n",
    "Y = tf.placeholder(tf.float32,[None,1])\n",
    "W = tf.Variable(tf.ones([n_dim,1]))\n",
    "bias = tf.Variable([0.5])\n",
    "\n",
    "linear_model = tf.matmul(X, W) + bias\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code builds a tensor to compute the cost of our model and builds a tensor to perform gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(linear_model - Y))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this code will actually train our weights and bias for us, and every 10 training iterations we will be appending our model's cost to our cost history array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(0, training_epochs):\n",
    "    sess.run(training_step,feed_dict={X:train_x,Y:train_y})\n",
    "    if epoch > 0 and epoch % 10 == 0:\n",
    "        cost_history.append(sess.run(cost,feed_dict={X: train_x,Y: train_y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will visualize our cost history array in order to see how quickly the model's error goes down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff78d973080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will print our model's MSE on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 19.907943\n"
     ]
    }
   ],
   "source": [
    "yhat = sess.run(linear_model, feed_dict={X: test_x})\n",
    "mse = tf.reduce_mean(tf.square(yhat - test_y))\n",
    "print(\"MSE: %f\" % sess.run(mse)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
