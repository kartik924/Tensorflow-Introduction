{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Image Classifier\n",
    "\n",
    "In This tutorial we will build an Image Classifier for the MNIST Data Set using a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will import the MNIST Handwritten digits data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding our Dataset\n",
    "\n",
    "Recall that the MNIST Handwritten Digits Dataset is a collection of images of handwritten digits. These images are all 28 by 28 pixels and are in grayscale instead of RGB. The dataset from the tensorflow library has 3 sets of images. Each of them have associated labels, and each set has a different number of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of images in image set 1:  55000\n",
      "# of images in image set 2:  5000\n",
      "# of images in image set 3:  10000\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(mnist)):\n",
    "    print('# of images in image set %d: ' % (i + 1), len(mnist[i].images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are using matplotlib to display the first dataset's first image. We are also printing out the label associated with this image. Clearly the image looks like the number 7, And thus the label is an array of 0s where the 7th index is a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label of this image:  [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wOQv/IG3GepCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd92490b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist[0].images[0].reshape((28, 28)), cmap=\"Greys\")\n",
    "print('Label of this image: ', mnist[0].labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Network\n",
    "Now that we understand our dataset, lets start building a neural network to classify it. First, we need to define the image size, and number of classes. Then, we need to define our input and output tensors according to the image size and number of classes. Since we will be performing matrix multiplication with our tensors, we must make them of rank 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32) Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28 * 28\n",
    "classes = 10 \n",
    "\n",
    "x = tf.placeholder('float32', [None, image_size])\n",
    "y = tf.placeholder('float32', [None, classes])\n",
    "\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a neural network has weights from each node in one layer to each node in the next layer, and a bias from one layer to each node in the next layer. We will construct a neural network with only one hidden layer with 256 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = {'input_to_h1': tf.Variable(tf.random_normal([image_size, 256])), \n",
    "           'h1_to_output': tf.Variable(tf.random_normal([256, classes]))}\n",
    "\n",
    "biases = { 'input_to_h1': tf.Variable(tf.random_normal([256])), \n",
    "           'h1_to_output': tf.Variable(tf.random_normal([classes]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have randomly initialized weights and biases, we can construct a tensor to represent the entire neural network. Recall that a neural network performs matrix multiplication on the incoming nodes with their weights, so we will use tf.matmul to perform that operation. Note that this is synonymous to the 'linear_model = weights * x + bias' tensor we had in the introduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_layer = tf.add(tf.matmul(x, weights['input_to_h1']), biases['input_to_h1'])\n",
    "output_layer = tf.add(tf.matmul(hidden_layer, weights['h1_to_output']), biases['h1_to_output'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Neural Network\n",
    "Now that we have our basic model built, we should define an error tensor and a gradient_descent tensor, so that we can build a training tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = output_layer, labels = y))\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = gradient_descent.minimize(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be helpful to measure the accuracy of the model while training it so that we can interpret the performance of the neural network, so we can construct an accuracy tensor by checking whether or not our model determined the correct class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_correct = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y, 1))\n",
    "model_accuracy = tf.reduce_mean(tf.cast(prediction_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the pieces of the puzzle together (our model, an optimizer, and a performance measure), we can run our session by running our model's optimizer multiple times over different 'batches' of input data, and printing out the accuracy of our model over our iterations. Note that we are using a variant of gradient descent called mini-batch gradient descent. This is similar to stochastic gradient descent with the exception that instead of updating our model on every data point, we update our model on a small group of our data points. Mini-batch strikes a good balance between performance and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0 Network Accuracy:  0.04\n",
      "iteration:  100 Network Accuracy:  0.72\n",
      "iteration:  200 Network Accuracy:  0.81\n",
      "iteration:  300 Network Accuracy:  0.81\n",
      "iteration:  400 Network Accuracy:  0.81\n",
      "iteration:  500 Network Accuracy:  0.77\n",
      "iteration:  600 Network Accuracy:  0.91\n",
      "iteration:  700 Network Accuracy:  0.76\n",
      "iteration:  800 Network Accuracy:  0.88\n",
      "iteration:  900 Network Accuracy:  0.83\n",
      "Gradient Descent complete\n",
      "testing acc:  0.8524\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(0, 1000):\n",
    "        batch_x, batch_y = mnist.train.next_batch(100)\n",
    "        \n",
    "        sess.run(train, {x: batch_x, y: batch_y})\n",
    "        if i % 100 == 0 or i == 0:\n",
    "            loss, acc = sess.run([error, model_accuracy], {x: batch_x, y: batch_y})\n",
    "            \n",
    "            print('iteration: ', i, 'Network Accuracy: ', sess.run(model_accuracy, {x: batch_x, y: batch_y}))\n",
    "            \n",
    "    print('Gradient Descent complete')\n",
    "    \n",
    "    print('testing acc: ', sess.run(model_accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you have built your first Neural Network with TensorFlow!\n",
    "\n",
    "## Activity 1:\n",
    "\n",
    "Export a graph of this session to TensorBoard to visualize and understand the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 2:\n",
    "Tune the parameters (learning rate, # of iterations, # of images read, # of hidden layers, # of nodes in hidden layers, activation functions, etc), in order to maximize the accuracy of your network. Try to beat a base test accuracy of 93%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Solution:\n",
    "\n",
    "- Adding one more hidden layer with same # of hidden nodes (256)\n",
    "- Applying relu to both hidden layers\n",
    "- Reducing the learning rate\n",
    "- Increasing the # batches to 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0 Network Accuracy:  0.22\n",
      "iteration:  1000 Network Accuracy:  0.94\n",
      "iteration:  2000 Network Accuracy:  0.92\n",
      "iteration:  3000 Network Accuracy:  0.98\n",
      "iteration:  4000 Network Accuracy:  0.92\n",
      "iteration:  5000 Network Accuracy:  0.99\n",
      "iteration:  6000 Network Accuracy:  0.93\n",
      "iteration:  7000 Network Accuracy:  0.99\n",
      "iteration:  8000 Network Accuracy:  0.99\n",
      "iteration:  9000 Network Accuracy:  1.0\n",
      "iteration:  10000 Network Accuracy:  0.99\n",
      "iteration:  11000 Network Accuracy:  0.99\n",
      "iteration:  12000 Network Accuracy:  0.99\n",
      "iteration:  13000 Network Accuracy:  0.99\n",
      "iteration:  14000 Network Accuracy:  0.99\n",
      "iteration:  15000 Network Accuracy:  0.98\n",
      "iteration:  16000 Network Accuracy:  1.0\n",
      "iteration:  17000 Network Accuracy:  1.0\n",
      "iteration:  18000 Network Accuracy:  1.0\n",
      "iteration:  19000 Network Accuracy:  1.0\n",
      "iteration:  20000 Network Accuracy:  1.0\n",
      "iteration:  21000 Network Accuracy:  0.98\n",
      "iteration:  22000 Network Accuracy:  1.0\n",
      "iteration:  23000 Network Accuracy:  1.0\n",
      "iteration:  24000 Network Accuracy:  1.0\n",
      "iteration:  25000 Network Accuracy:  1.0\n",
      "iteration:  26000 Network Accuracy:  1.0\n",
      "iteration:  27000 Network Accuracy:  1.0\n",
      "iteration:  28000 Network Accuracy:  1.0\n",
      "iteration:  29000 Network Accuracy:  1.0\n",
      "Gradient Descent complete\n",
      "testing acc:  0.9401\n"
     ]
    }
   ],
   "source": [
    "image_size = 28 * 28\n",
    "classes = 10 \n",
    "hidden_layer_size = 256\n",
    "\n",
    "x = tf.placeholder('float32', [None, image_size])\n",
    "y = tf.placeholder('float32', [None, classes])\n",
    "\n",
    "weights = {'input_to_h1': tf.Variable(tf.random_normal([image_size, hidden_layer_size])), \n",
    "           'h1_to_h2': tf.Variable(tf.random_normal([hidden_layer_size, hidden_layer_size])),\n",
    "           'h2_to_output': tf.Variable(tf.random_normal([hidden_layer_size, classes]))}\n",
    "\n",
    "biases = { 'input_to_h1': tf.Variable(tf.random_normal([hidden_layer_size])), \n",
    "           'h1_to_h2': tf.Variable(tf.random_normal([hidden_layer_size])),\n",
    "           'h2_to_output': tf.Variable(tf.random_normal([classes]))}\n",
    "\n",
    "hidden_layer1 = tf.add(tf.matmul(x, weights['input_to_h1']), biases['input_to_h1'])\n",
    "hidden_layer1 = tf.nn.relu(hidden_layer1)\n",
    "hidden_layer2 = tf.add(tf.matmul(hidden_layer1, weights['h1_to_h2']), biases['h1_to_h2'])\n",
    "hidden_layer2 = tf.nn.relu(hidden_layer2)\n",
    "output_layer = tf.add(tf.matmul(hidden_layer2, weights['h2_to_output']), biases['h2_to_output'])\n",
    "\n",
    "error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = output_layer, labels = y))\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(0.005)\n",
    "train = gradient_descent.minimize(error)\n",
    "\n",
    "prediction_correct = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y, 1))\n",
    "model_accuracy = tf.reduce_mean(tf.cast(prediction_correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(0, 30000):\n",
    "        batch_x, batch_y = mnist.train.next_batch(100)\n",
    "        \n",
    "        sess.run(train, {x: batch_x, y: batch_y})\n",
    "        if i % 1000 == 0 or i == 0:\n",
    "            loss, acc = sess.run([error, model_accuracy], {x: batch_x, y: batch_y})\n",
    "            \n",
    "            print('iteration: ', i, 'Network Accuracy: ', sess.run(model_accuracy, {x: batch_x, y: batch_y}))\n",
    "            \n",
    "    print('Gradient Descent complete')\n",
    "    \n",
    "    print('testing acc: ', sess.run(model_accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
